---
title: "Lab 15 - Regularization"
output: html_notebook
---

Read in data
```{r}
library(tidyverse)
library(ggplot2)
nba_lineups = readRDS("../data/15_nba-lineups.rds")
head(nba_lineups)
```

15.1.4 1 - One hot encode players in the dataset 

```{r}
nba_lineups_fast <- nba_lineups %>%
  mutate(
    home_ids = str_extract_all(lineup_team, "\\d+"),
    away_ids = str_extract_all(lineup_opp, "\\d+"),
    all_ids  = map2(home_ids, away_ids, ~ unique(c(.x, .y))),
    row_id   = row_number()
  )

long_ids <- nba_lineups_fast %>%
  select(row_id, all_ids) %>%
  unnest(all_ids, keep_empty=TRUE)

one_hot <- long_ids %>%
  mutate(value = 1) %>%
  pivot_wider(names_from = all_ids, values_from = value, values_fill = 0, names_prefix = "player_") 

nba_encoded <- nba_lineups_fast %>%
  left_join(one_hot, by = "row_id")

```


2 - fit with OLS 

```{r}

one_hot_input <- one_hot %>% 
  select(-row_id)

ols_model <- lm(pts_poss ~ . -1 , data = cbind(pts_poss = nba_encoded$pts_poss, one_hot_input))
```


```{r}
summary(ols_model)
```
3 - Ridge model
```{r}
library ( glmnet )
# set lambdas to crossâˆ’validate
X <- as.matrix(one_hot_input)

# 2. Response vector
y <- nba_encoded$pts_poss

# 3. Define lambda grid
lambdas <- 10^seq(-3, 3, by = 0.2)

# 4. Fit ridge regression model (alpha = 0)
ridge_model <- cv.glmnet(
  x = X,
  y = y,
  nfolds = 5,
  alpha = 0,              # ridge
  family = "gaussian",
  lambda = lambdas,
  standardize = TRUE
)

# 5. Output the best lambda
ridge_model$lambda.min

# 6. Plot cross-validation curve
plot(ridge_model)
```
```{r}

ols_df <- coef(ols_model) %>%
  as.data.frame() %>%
  rownames_to_column("player_id") %>%
  rename(coefficient = 2) %>%
  filter(player_id != "(Intercept)") %>%
  mutate(model = "OLS")
  
```

4 - Visualize the two models 

```{r}
name_id_map <- nba_lineups %>%
  select(lineup_team, lineup_opp) %>%
  pivot_longer(cols = everything(), values_to = "lineup") %>%
  separate_rows(lineup, sep = ",\\s*") %>%  # Split comma-separated names
  distinct(lineup) %>%
  mutate(
    player_id = str_extract(lineup, "\\d+"),
    player_name = str_trim(str_remove(lineup, "\\d+"))  # remove digits
  )
```

```{r}
ridge_coef <- coef(ridge_model, s = "lambda.min")

ridge_df <- coef(ridge_model, s = "lambda.min") %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column("player_id") %>%
  rename(coefficient = 2) %>%
  filter(player_id != "(Intercept)") %>%
  mutate(model = "Ridge")

combined_df <- bind_rows(ols_df, ridge_df) %>% 
  mutate(player_id = str_remove(player_id, "^player_")) %>%
  left_join(name_id_map, by = "player_id")

top_players <- combined_df %>%
  group_by(player_name) %>%
  summarise(avg_coef = mean(coefficient)) %>%
  arrange(desc(avg_coef)) %>%
  slice(1:15) %>%
  pull(player_name)

plot_df <- combined_df %>%
  filter(player_name %in% top_players) %>%
  mutate(player_name = factor(player_name, levels = rev(top_players)))

ggplot(plot_df, aes(x = player_name, y = coefficient, fill = model)) +
  geom_col(position = position_dodge(width = 0.7)) +
  coord_flip() +
  labs(
    title = "Player Coefficients: OLS vs Ridge Regression",
    x = "Player",
    y = "Estimated Effect on Points per Possession"
  ) +
  scale_fill_manual(values = c("OLS" = "lightblue4", "Ridge" = "lightcoral")) +
  theme_minimal()

```

```{r}
library(caret)
#out of sample performance
set.seed(12345)  # reproducible split

n <- nrow(X)
train_idx <- sample(seq_len(n), size = 0.8 * n)

X_train <- X[train_idx, ]
X_test  <- X[-train_idx, ]
y_train <- y[train_idx]
y_test  <- y[-train_idx]

#ols
ols_model <- lm(y_train ~ X_train - 1)  # remove intercept
y_pred_ols <- as.vector(predict(ols_model, newdata = as.data.frame(X_test)))

#ridge 
ridge_model <- cv.glmnet(X_train, y_train, alpha = 0, nfolds = 5)
y_pred_ridge <- predict(ridge_model, newx = X_test, s = "lambda.min")

rmse_ols <- RMSE(y_pred_ols, y_test)
rmse_ridge <- RMSE(y_pred_ridge, y_test)

print(c(OLS = rmse_ols, Ridge = rmse_ridge))
```

Visualize players' avg pts per poessession and comapre to models
```{r}
#data preparation to merge on row_id to reincorporate players back into data 
row_ids <- nba_encoded$row_id
row_ids_test <- row_ids[-train_idx]

player_map <- nba_lineups_fast %>%
  select(row_id, all_ids) %>%
  mutate(player_id = sapply(all_ids, function(x) paste(x, collapse = ","))) %>%
  select(row_id, player_id)

  
# Join player info back to test predictions
df_pred <- data.frame(
  row_id = row_ids_test,
  actual = y_test,
  ols = y_pred_ols,
  ridge = as.vector(y_pred_ridge)
) %>%
  left_join(player_map, by = "row_id") %>% 
  separate_rows(player_id, sep = ",") %>% 
  mutate(player_id = str_remove(player_id, "^player_")) %>%
  left_join(name_id_map, by = "player_id") 

head(df_pred)

```

```{r}
#group by
df_pred_grouped <- df_pred %>% 
  group_by(player_name) %>%
  summarise(
    mean_actual = mean(actual, na.rm = TRUE),
    mean_ols = mean(ols, na.rm = TRUE),
    mean_ridge = mean(ridge, na.rm = TRUE)
  ) %>%
  ungroup()

ggplot(df_pred_grouped, aes(x = mean_actual, y = mean_ols, color = "OLS")) +
  geom_point(alpha = 0.5) +
  geom_point(aes(x = mean_actual, y = mean_ridge, color = "Ridge"), alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  labs(
    title = "Average Points per Possession: Actual vs OLS and Ridge Predictions",
    x = "Actual Points per Possession",
    y = "Predicted Points per Possession"
  ) +
  scale_color_manual(values = c("OLS" = "lightblue3", "Ridge" = "lightcoral")) +
  theme_minimal()
```

We can see that the ridge estimator is much more accurate and likely more sensitive to the data, whereas the OLS almost predicts the same amount for most players

```{r}
#bar chart for random sample of 15 players
sample_players <- sample(unique(df_pred_grouped$player_name), 15)


ggplot( df_pred_grouped %>% filter(player_name %in% sample_players)) +
  geom_col(aes(x = player_name, y = mean_actual, fill = "Actual"),  alpha = 0.8, width = 0.4) +
  geom_col(aes(x = player_name, y = mean_ols, fill = "OLS"), alpha = 0.6, width = 0.4) +
  geom_col(aes(x = player_name, y = mean_ridge, fill = "Ridge"), alpha = 0.6, width = 0.4) +
  labs(
    title = "Predicted vs Actual Points per Possession by Player",
    x = "Player",
    y = "Points per Possession"
  ) +
  scale_fill_manual(name = "Model", values = c("Actual" = "black", "OLS" = "darkturquoise", "Ridge" = "deeppink")) +
  theme_minimal() +
  coord_cartesian(ylim = c(.95, 1.25))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  theme(legend)
```

Use LASSO regression

```{r}
#same code as earlier but alpha = 1
lasso_model <- cv.glmnet(
  x = X,
  y = y,
  nfolds = 5,
  alpha = 1,              
  family = "gaussian",
  lambda = lambdas,
  standardize = TRUE
)

# 5. Output the best lambda
lasso_model$lambda.min

# 6. Plot cross-validation curve
plot(lasso_model)
```

Visualize results 

```{r}
lasso_coef <- coef(lasso_model, s = "lambda.min")

lasso_df <- coef(lasso_model, s = "lambda.min") %>%
  as.matrix() %>%
  as.data.frame() %>%
  rownames_to_column("player_id") %>%
  rename(coefficient = 2) %>%
  filter(player_id != "(Intercept)") %>%
  mutate(model = "Lasso")

head(lasso_df)

all_results = bind_rows(ols_df, ridge_df, lasso_df) %>% 
  mutate(player_id = str_remove(player_id, "^player_")) %>%
  left_join(name_id_map, by = "player_id")  
  
top_all <- all_results %>% 
  group_by(player_name) %>%
  summarise(avg_coef = mean(coefficient)) %>%
  arrange(desc(avg_coef)) %>%
  slice(1:15) %>%
  pull(player_name)

plot_all_df <- all_results %>%
  filter(player_name %in% top_all) %>%
  mutate(player_name = factor(player_name, levels = rev(top_all))) 

ggplot(plot_all_df, aes(x = player_name, y = coefficient, fill = model)) +
  geom_col(position = position_dodge(width = 0.7)) +
  coord_flip() +
  labs(
    title = "Player Coefficients: OLS vs Ridge Regression",
    x = "Player",
    y = "Estimated Effect on Points per Possession"
  ) +
  scale_fill_manual(values = c("OLS" = "lightblue4", "Ridge" = "lightcoral", "Lasso" = 'palegoldenrod')) +
  theme_minimal()
```
We see that many players' coefficients have been eliminated with LASSO, since it can regress completely to 0. We can now compare out of sample performance of the models 

```{r}
lasso_model <- cv.glmnet(X_train, y_train, alpha = 1, nfolds = 5)
y_pred_lasso <- predict(lasso_model, newx = X_test, s = "lambda.min")
rmse_ols <- RMSE(y_pred_ols, y_test)
rmse_ridge <- RMSE(y_pred_ridge, y_test)
rmse_lasso <- RMSE(y_pred_lasso, y_test)
```
```{r}
print(c(OLS = rmse_ols, Ridge = rmse_ridge, Lasso = rmse_lasso), digits = 8)
```

```{r}
df_pred <- data.frame(
  row_id = row_ids_test,
  actual = y_test,
  ols = y_pred_ols,
  ridge = as.vector(y_pred_ridge),
  lasso = as.vector(y_pred_lasso)
) %>%
  left_join(player_map, by = "row_id") %>%
  separate_rows(player_id, sep = ",") %>%
  mutate(player_id = str_remove(player_id, "^player_")) %>%
  left_join(name_id_map, by = "player_id")

df_pred_grouped <- df_pred %>%
  group_by(player_name) %>%
  summarise(
    mean_actual = mean(actual, na.rm = TRUE),
    mean_ols = mean(ols, na.rm = TRUE),
    mean_ridge = mean(ridge, na.rm = TRUE),
    mean_lasso = mean(lasso, na.rm = TRUE)
  ) %>%
  ungroup()

ggplot(df_pred_grouped, aes(x = mean_actual)) +
  geom_point(aes(y = mean_ols, color = "OLS"), alpha = 0.5) +
  geom_point(aes(y = mean_ridge, color = "Ridge"), alpha = 0.5) +
  geom_point(aes(y = mean_lasso, color = "Lasso"), alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  labs(
    title = "Average Points per Possession: Actual vs Model Predictions",
    x = "Actual Points per Possession",
    y = "Predicted Points per Possession"
  ) +
  scale_color_manual(values = c("OLS" = "lightblue4", 
                                "Ridge" = "lightcoral", 
                                "Lasso" = "palegoldenrod")) +
  theme_minimal()
```
We see that the performance so far looks similar to ridge but the points may be slightly more clustered 

```{r}
sample_players <- sample(unique(df_pred_grouped$player_name), 15)



ggplot(df_pred_grouped %>% filter(player_name %in% sample_players)) +
  geom_col(aes(x = player_name, y = mean_actual, fill = "Actual"), alpha = 0.8, width = 0.4) +
  geom_col(aes(x = player_name, y = mean_ols, fill = "OLS"), alpha = 0.6, width = 0.4) +
  geom_col(aes(x = player_name, y = mean_ridge, fill = "Ridge"), alpha = 0.6, width = 0.4) +
  geom_col(aes(x = player_name, y = mean_lasso, fill = "Lasso"), alpha = 0.6, width = 0.4) +
  labs(
    title = "Predicted vs Actual Points per Possession by Player",
    x = "Player",
    y = "Points per Possession"
  ) +
  scale_fill_manual(
    name = "Model",
    values = c("Actual" = "black", 
               "OLS" = "darkturquoise", 
               "Ridge" = "deeppink", 
               "Lasso" = "royalblue")
  ) +
  theme_minimal() +
  coord_cartesian(ylim = c(0.95, 1.25)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r fig.width = 12, fig.height = 6}
df_long <- df_pred_grouped %>%
  pivot_longer(
    cols = c(mean_ols, mean_ridge, mean_lasso),
    names_to = "model",
    values_to = "predicted"
  ) %>%
  mutate(
    model = case_when(
      model == "mean_ols" ~ "OLS",
      model == "mean_ridge" ~ "Ridge",
      model == "mean_lasso" ~ "Lasso",
      TRUE ~ model
    )
  )

ggplot(df_long %>% filter(player_name %in% sample_players)) +
  geom_col(aes(x = player_name, y = mean_actual, fill = "Actual"), alpha = 0.8, width = 0.4) +
  geom_col(aes(x = player_name, y = predicted, fill = model),
           width = 0.3, alpha = 0.8, position = position_nudge(x = 0.15)) +
  facet_wrap(~ model, scales = "free_y") +
  labs(
    title = "Predicted vs Actual Points per Possession by Model",
    x = "Player",
    y = "Points per Possession"
  ) +
  scale_fill_manual(
    name = "Legend",
    values = c("Actual" = "black", "OLS" = "lightblue4", "Ridge" = "lightcoral", "Lasso" = "palegoldenrod")
  ) +
  theme_minimal() +
  theme(strip.text = element_text(size = 16)) +
  coord_cartesian(ylim = c(0.95, 1.2)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
It's difficult to tell based off these plots and since the RMSE was similar for all the models, but it looks like the LASSO performs better on the middle of the data points but ridge fits slightly better on outliers, such as Sidy Cissoko. OLS is also good in the middle, but much less sensitive to outliers, even mild ones such as Rayan Rupert.
